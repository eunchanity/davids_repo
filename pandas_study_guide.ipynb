{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing csv through pandas\n",
    "#setting default index to a specific column\n",
    "\n",
    "df = pd.read_csv('data_2019/survey_results_public.csv', index_col='Respondent')\n",
    "schema_df = pd.read_csv('data_2019/survey_results_schema.csv', index_col='Column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing display views\n",
    "pd.set_option('display.max_columns',85)\n",
    "pd.set_option('display.max_rows',85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data viewing methods\n",
    "\n",
    "df.head()\n",
    "df.tail()\n",
    "df.sample(int, random_state=int)\n",
    "df.shape\n",
    "df.info()\n",
    "df.columns\n",
    "df.values\n",
    "df.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling values\n",
    "\n",
    "#for columns:\n",
    "    df['column']\n",
    "#for rows: \n",
    "    df.loc['row','column']\n",
    "\n",
    "    df.iloc #is for integer values only for row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manipulating index\n",
    "\n",
    "df.sort_index()\n",
    "df.sort_index(ascending=False)\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index('column', inplace=True)\n",
    "\n",
    "#inplace is to hard write into original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering, conditional filtering\n",
    "\n",
    "df[filt] #after creating a variable 'filt' that meets a desired criteria\n",
    "df[some_created_filter] #you can also put the filter directly into bracket\n",
    "df.loc[filt, 'column']\n",
    "\n",
    "df.loc[conditional] \n",
    "    df.loc[conditional,'column']\n",
    "    df.loc[filt, 'column'] = 'newvalue'\n",
    "    df.loc[df['column']=='value', ['column1', 'column2']] == ['newval1', 'newval2']\n",
    "        \n",
    "& #and\n",
    "| #or\n",
    "~ #opposite\n",
    "\n",
    "#examples\n",
    "countries = ['United States','India','United Kingdom','Germany','Canada']\n",
    "filt = df['Country'].isin(countries)\n",
    "df.loc[filt,['Country','LanguageWorkedWith','ConvertedComp']]\n",
    "\n",
    "filt = df['LanguageWorkedWith'].str.contains('Python', na=False)\n",
    "\n",
    "#pokemon example - filtering out Megas\n",
    "df.loc[~df['Name'].str.contains('Mega')].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying existing columns\n",
    "\n",
    "df.columns = ['change','names','of','all','columns']\n",
    "df.columns = [x.upper() for x in df.columns]\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "\n",
    "#only change some columns? - pass in dictionary\n",
    "df.rename(columns={'old_name':'new_name'}, inplace=True)\n",
    "\n",
    "#modifying existing rows\n",
    "df.loc['row_label'] = ['list','of','all','row','values']\n",
    "df.loc['row_label',['list','of','columns']] = ['list','of','new_values']\n",
    "df.loc['row_label','column'] = 'new_value'\n",
    "df.at['row_label','column'] = 'new_value' #only for single value replacement\n",
    "\n",
    "df.loc[filt,'column'] = 'new_value'\n",
    "\n",
    "#changing multiple rows\n",
    "df['column'] = df['column'].str.lower() #lowercase version of all values in the column\n",
    "\n",
    "#changing specific values within the string\n",
    "df['column'] = df['column'].str.replace('\\d+', '') #removing one or more digits from str\n",
    "    #look up regex cheat sheet to find more characters and quantifiers\n",
    "\n",
    "\n",
    "#methods\n",
    "apply\n",
    "#in series\n",
    "df['column'].apply(len) #gives length of values in column\n",
    "df['column'] = df['column'].apply(some_function) #no parens in function, function is for more complicated stuff\n",
    "df['column'] = df['column'].apply(lambda x: x.method())\n",
    "\n",
    "#in dataframe\n",
    "df.apply(pd.Series.min) #min value\n",
    "df.apply(lambda x:x.min())\n",
    "\n",
    "#changing every value in DATAFRAME? use applymap\n",
    "df.applymap(len)\n",
    "df.applymap(str.lower)\n",
    "\n",
    "#changing every value in SERIES? use map\n",
    "df['column'].map({'Corey':'Chris', 'Jane':'Mary'}) #no substitute turns all to N/A\n",
    "\n",
    "#don't want to change every value in series? use replace\n",
    "df['column'].replace({'Corey':'Chris','Jane':'Mary'})\n",
    "\n",
    "#REMEMBER!!!! in order to permanently change stuff, need to overwrite with ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding columns in dataframes\n",
    "df['new_column'] = df['column1'] + ' ' + df['column2']\n",
    "\n",
    "#removing columns in dataframes\n",
    "df.drop(columns=['name','of','columns'], inplace=True)\n",
    "\n",
    "#splitting columns\n",
    "df['column'].str.split(' ', expand=True)\n",
    "df[['column1','column2']] = df['column'].str.split(' ', expand=True)\n",
    "\n",
    "#adding rows in dataframe\n",
    "df.append({'column', 'new_value'}, ignore_index=True)\n",
    "\n",
    "#adding dataframes together\n",
    "df = df.append(df2, ignore_index=True, sort=False)\n",
    "\n",
    "#removing rows in dataframe\n",
    "df.drop(index=4, inplace=True)\n",
    "\n",
    "df.drop(index=df[df['column'] == 'value'.index])\n",
    "OR\n",
    "filt = df['column'] == 'value'\n",
    "df.drop(index=df[filt].index)\n",
    "\n",
    "#merge/combine tables\n",
    "df3 = pd.merg(df1, df2, on='commonvalue') #pandas merge\n",
    "df3 = df1.merge(df2,\n",
    "                 left_on=['userid','date'], #merge to df1\n",
    "                 right_on=['userid','date_x'], #merge to df2\n",
    "                 right_index=True, #use index from df2\n",
    "                 how='left') #use OG from df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting data\n",
    "df.sort_values(by='column', ascending=False) \n",
    "df.sort_index() #sort by default index number\n",
    "\n",
    "#sorting after duplicates?\n",
    "df.sort_values(by=['column1','column2'], ascending=False) #list for order of sort\n",
    "df.sort_values(by=['column1','column2'], ascending=[False, True], inplace=True) #booleans for sorting order per column\n",
    "\n",
    "#extracting sorted series\n",
    "df['column'].sort_values()\n",
    "\n",
    "#want the top/low 10?\n",
    "df['column'].nlargest(10)\n",
    "df['column'].nsmallest(10)\n",
    "df.nlargest(10, 'ConvertedComp') #all other answers by top 10 salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregating data\n",
    "\n",
    "df.describe()\n",
    "df['column'].median() #mean is too affected by outliers so median is sometimes better\n",
    "df.count()\n",
    "df.nameofcolumn.value_counts(normalize=True) #counts for unique values, normalize shows percentage\n",
    "df.nameofcolumn.value_counts().plot(kind='barh')\n",
    "df['column'].unique()\n",
    "\n",
    "#grouping data\n",
    "df.groupby(['column1','column2']) #subset grouping\n",
    "df.groupby(['column1','column2']).somecolumn.agg(['count', 'mean']) #single column, multiple methods\n",
    "df.groupby(['column1','column2',])[['column3', 'column4']].agg(['count', 'mean']) #multiple columns, multiple methods\n",
    "df.groupby(['column1','column2']).agg({'column3': 'mean', 'column4': 'sum'}) #specific column, specific method\n",
    "\n",
    "df.groupby(['column1', 'column2'], as_index=False).price.sum() #return a flat table\n",
    "\n",
    "          #[firstparen for grouping][secondparen for applying methods]\n",
    "\n",
    "    \n",
    "#example\n",
    "variable_name = df.groupby(['Country'])\n",
    "variable_name.get_group('United States') #all answers for that group 'United States'\n",
    "variable_name['SocialMedia'].value_counts() #counts for 'SocialMedia' for all countries\n",
    "variable_name['SocialMedia'].value_counts().loc['United States'] #only for one country\n",
    "OR\n",
    "df[df.country == 'United States'].groupby(['SocialMedia']).somecolumn.mean()\n",
    "\n",
    "\n",
    "#grouping and then locating by specific values\n",
    "variable_name['ConvertedComp'].median().loc['United States']\n",
    "variable_name['ConvertedComp'].agg(['median','mean']).loc['United States'] #agg is to call multiple functions\n",
    "variable_name['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').sum())\n",
    "\n",
    "#concat series into new dataframe - example problem\n",
    "new_df = pd.concat([series1,series2], axis='columns', sort=False)\n",
    "\n",
    "python_df = pd.concat([country_respondents, country_python], axis='columns', sort=False)\n",
    "python_df.rename(columns={'Country': 'Total_Population', 'LanguageWorkedWith':'Knows_Python'}, inplace=True)\n",
    "python_df['Percentage_Python'] = 100*(python_df['Knows_Python'] / python_df['Total_Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data\n",
    "\n",
    "#checking nulls/NaN\n",
    "df[df.nameofcolumn.isnull()]\n",
    "df.isna() \n",
    "\n",
    "df.fillna('Replacingvalue', inplace=True)\n",
    "df.dropna(axis='index/columns', how='any/all') #removes NaN\n",
    "    df.dropna(axis='index',how='all', subset=['last','email'], inplace=True) #dropped if last AND email are missing\n",
    "\n",
    "#custom missing values\n",
    "\n",
    "\n",
    "#for created dataframes\n",
    "df.replace('NA', np.nan, inplace=True)\n",
    "df.replace('Missing', np.nan, inplace=True)\n",
    "\n",
    "#casting data types\n",
    "df.dtypes\n",
    "df.astype() #change evertyhing\n",
    "df['column'] = df['column'].astype(float) #change just one column\n",
    "\n",
    "#importing csv?\n",
    "na_vals = ['custom','NA','values']\n",
    "df = pd.read_csv('data_2019/survey_results_public.csv', index_col='Respondent', na_values=na_vals)\n",
    "\n",
    "#example\n",
    "df['column'].unique()\n",
    "df['column'].replace('string',int,inplace=True)\n",
    "df['column'] = df['column'].astype(float)\n",
    "df['column'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date and time series data\n",
    "df['column'] = pd.to_datetime(df['column'], format='%Y-%m-%d %I-%p') #may need to format date\n",
    "\n",
    "d_parser = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %I-%p')\n",
    "df = pd.read_csv('CSVfile.csv', parse_dates=['Date'], date_parser=d_parser)\n",
    "\n",
    "#date/time method\n",
    "df.loc['index','column'].day_name() #for one value\n",
    "df['Date'].dt.day_name() #for entire series\n",
    "df['DayofWeek'] = df['Date'].dt.day_name() #adding new column for day\n",
    "\n",
    "df['column'].min()\n",
    "df['column'].max()\n",
    "df['column'].max() - df['column'].min() #timedelta\n",
    "\n",
    "filt = (df['column'] >= '2019') & (df['column'] < '2020') #using filt for a date range\n",
    "OR filt = (df['column'] >= pd.to_datetime('2019-01-01')) & (df['column'] < pd.to_datetime('2020-01-01'))\n",
    "df.loc[filt]\n",
    "\n",
    "df.set_index('Date', inplace=True) #setting datetime as index\n",
    "df.loc['2019']\n",
    "df['2020-01':'2020-02'] #using index for a date range\n",
    "    df['2020-01':'2020-02']['Close'].mean()\n",
    "\n",
    "\n",
    "#resampling\n",
    "highs = df['High'].resample('D').max() #resample the datetimes by day and get max value\n",
    "highs['2020-01-01']\n",
    "    = df['2020-01-01']['High'].max()\n",
    "\n",
    "#plotting the data\n",
    "%matplotlib inline\n",
    "highs.plot()\n",
    "\n",
    "#resampling multiple columns\n",
    "df.resample('W').agg.({'Close': 'mean', 'High': 'max', 'Low': 'min', 'Volume': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading/writing different types of files\n",
    "\n",
    "#csv\n",
    "df = pd.read_csv('filepath.csv', index_col='selectedindex')\n",
    "new_df.to_csv('newfilepath.csv')\n",
    "\n",
    "#tab-limited file\n",
    "df = pd.read_csv('filepath.tsv', index_col='selectedindex', sep='\\t , etc.')\n",
    "new_df.to_csv('newfilepath.tsv', sep='\\t , etc.')\n",
    "\n",
    "#excel\n",
    "df = pd.read_excel('filepath.xlsx', index_col='selectedindex')\n",
    "new_df.to_excel('newfilepath.xlsx')\n",
    "\n",
    "#json\n",
    "df = pd.read_json('filepath.json', orient='records', lines=True)\n",
    "new_df.to_json('newfilepath.json', orient='records', lines=True) #default dictionary-like\n",
    "\n",
    "#sql\n",
    "pip install SQLAlchemy #for sql\n",
    "pip install psycopg2-binary #for postgres\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "engine = create_engine('postgresql'://user:password@localhost:portnumber/data_base) #database connection\n",
    "\n",
    "new_df.to_sql('data_table', engine, if_exists='replace/append/etc')\n",
    "df = pd.read_sql('data_table', engine, index_col='selectedindex')\n",
    "df = pd.read_sql_query('SELECT * FROM data_table', engine, index_col='selectedindex') #running a query\n",
    "\n",
    "\n",
    "#url - depends on the type of data in url\n",
    "df = pd.read_json/csv/etc('pasteurlhere', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex\n",
    "import re"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
